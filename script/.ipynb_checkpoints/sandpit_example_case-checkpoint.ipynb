{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "850fc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc2a0c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b973831",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f95766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sr.AudioFile('data/test_audio_four.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ece97c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with test as source:\n",
    "    audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea4816e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.AudioData"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f258a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"figure 2 shows an example of processing of speech using him and your models yeah it's lovely when it's time for taking your mother really vehicle off the boys related to sell tickets to Troy control actually child health and beauty cases from within 4 for the first time in 10 years research and development programs use proprietary McIntosh traffic\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1ad024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "import sys\n",
    "import os\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e3f8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SetLogLevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28780238",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = wave.open('data/harvard_sentence_one.wav', \"rb\")\n",
    "if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "    print (\"Audio file must be WAV format mono PCM.\")\n",
    "    exit (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd7b03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(lang=\"en-us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7acfa8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = KaldiRecognizer(model, wf.getframerate())\n",
    "rec.SetWords(True)\n",
    "rec.SetPartialWords(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d355183c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Wave_read' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9fca10ead995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAcceptWaveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Wave_read' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    data = wf.readframes(16000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if rec.AcceptWaveform(data):\n",
    "        print(rec.Result())\n",
    "    else:\n",
    "        print(rec.PartialResult())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6596e63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\" : [{\n",
      "      \"conf\" : 1.000000,\n",
      "      \"end\" : 0.300000,\n",
      "      \"start\" : 0.090000,\n",
      "      \"word\" : \"i\"\n",
      "    }, {\n",
      "      \"conf\" : 1.000000,\n",
      "      \"end\" : 0.660000,\n",
      "      \"start\" : 0.300000,\n",
      "      \"word\" : \"believe\"\n",
      "    }, {\n",
      "      \"conf\" : 0.783910,\n",
      "      \"end\" : 0.930000,\n",
      "      \"start\" : 0.660000,\n",
      "      \"word\" : \"you're\"\n",
      "    }, {\n",
      "      \"conf\" : 1.000000,\n",
      "      \"end\" : 1.140000,\n",
      "      \"start\" : 0.930000,\n",
      "      \"word\" : \"just\"\n",
      "    }, {\n",
      "      \"conf\" : 1.000000,\n",
      "      \"end\" : 1.590000,\n",
      "      \"start\" : 1.170000,\n",
      "      \"word\" : \"talking\"\n",
      "    }, {\n",
      "      \"conf\" : 1.000000,\n",
      "      \"end\" : 2.520000,\n",
      "      \"start\" : 1.590000,\n",
      "      \"word\" : \"nonsense\"\n",
      "    }],\n",
      "  \"text\" : \"i believe you're just talking nonsense\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(rec.FinalResult())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a085c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71378c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames read: 1013 length: 2026\n",
      "not a whole number of frames\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import audioop\n",
    "\n",
    "inFileName = 'data/harvard_sentence_one.wav'\n",
    "outFileName = 'data/harvard_sentence_output.wav'\n",
    "\n",
    "# read input file and write mono output file\n",
    "try:\n",
    "    # open the input and output files\n",
    "    inFile = wave.open(inFileName,'rb')\n",
    "    outFile = wave.open(outFileName,'wb')\n",
    "    # force mono\n",
    "    outFile.setnchannels(1)\n",
    "    # set output file like the input file\n",
    "    outFile.setsampwidth(inFile.getsampwidth())\n",
    "    outFile.setframerate(inFile.getframerate())\n",
    "    # read\n",
    "    soundBytes = inFile.readframes(inFile.getnframes())\n",
    "    print(\"frames read: {} length: {}\".format(inFile.getnframes(),len(soundBytes)))\n",
    "    # convert to mono and write file\n",
    "    monoSoundBytes = audioop.tomono(soundBytes, inFile.getsampwidth(), 1, 1)\n",
    "    outFile.writeframes(monoSoundBytes)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "finally:\n",
    "    inFile.close()\n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "837ae6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import sys\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9af2a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'RIFF\\x8eT\\t\\x00WAVEfmt \\x10\\x00\\x00\\x00\\x01\\x00\\x01\\x00@\\x1f\\x00\\x00\\x80>\\x00\\x00\\x02\\x00\\x10\\x00datajT\\t\\x00'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(lang=\"en-us\")\n",
    "\n",
    "# Large vocabulary free form recognition\n",
    "rec = KaldiRecognizer(model, 16000)\n",
    "\n",
    "# You can also specify the possible word list\n",
    "#rec = KaldiRecognizer(model, 16000, \"zero oh one two three four five six seven eight nine\")\n",
    "\n",
    "wf = open('data/harvard_sentence_one.wav', \"rb\")\n",
    "wf.read(44) # skip header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd58e004",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Failed to process waveform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-39d69171f750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAcceptWaveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/vosk/__init__.py\u001b[0m in \u001b[0;36mAcceptWaveform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvosk_recognizer_accept_waveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to process waveform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Failed to process waveform"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    data = wf.read(16000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if rec.AcceptWaveform(data):\n",
    "        res = json.loads(rec.Result())\n",
    "        print (res['text'])\n",
    "\n",
    "res = json.loads(rec.FinalResult())\n",
    "print (res['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
